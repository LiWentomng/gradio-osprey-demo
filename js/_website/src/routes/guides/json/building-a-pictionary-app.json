{"guide": {"name": "building-a-pictionary-app", "category": "other-tutorials", "pretty_category": "Other Tutorials", "guide_index": null, "absolute_index": 30, "pretty_name": "Building A Pictionary App", "content": "# Building a Pictionary App\n\nRelated spaces: https://huggingface.co/spaces/nateraw/quickdraw\nTags: SKETCHPAD, LABELS, LIVE\n\n## Introduction\n\nHow well can an algorithm guess what you're drawing? A few years ago, Google released the **Quick Draw** dataset, which contains drawings made by humans of a variety of every objects. Researchers have used this dataset to train models to guess Pictionary-style drawings. \n\nSuch models are perfect to use with Gradio's *sketchpad* input, so in this tutorial we will build a Pictionary web application using Gradio. We will be able to build the whole web application in Python, and will look like this (try drawing something!):\n\n<iframe src=\"https://abidlabs-draw2.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\n\nLet's get started! This guide covers how to build a pictionary app (step-by-step): \n\n1. [Set up the Sketch Recognition Model](#1-set-up-the-sketch-recognition-model)\n2. [Define a `predict` function](#2-define-a-predict-function)\n3. [Create a Gradio Interface](#3-create-a-gradio-interface)\n\n### Prerequisites\n\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained sketchpad model, also install `torch`.\n\n## 1. Set up the Sketch Recognition Model\n\nFirst, you will need a sketch recognition model. Since many researchers have already trained their own models on the Quick Draw dataset, we will use a pretrained model in this tutorial. Our model is a light 1.5 MB  model trained by Nate Raw, that [you can download here](https://huggingface.co/spaces/nateraw/quickdraw/blob/main/pytorch_model.bin). \n\nIf you are interested, here [is the code](https://github.com/nateraw/quickdraw-pytorch) that was used to train the model. We will simply load the pretrained model in PyTorch, as follows:\n\n```python\nimport torch\nfrom torch import nn\n\nmodel = nn.Sequential(\n    nn.Conv2d(1, 32, 3, padding='same'),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Conv2d(32, 64, 3, padding='same'),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Conv2d(64, 128, 3, padding='same'),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Flatten(),\n    nn.Linear(1152, 256),\n    nn.ReLU(),\n    nn.Linear(256, len(LABELS)),\n)\nstate_dict = torch.load('pytorch_model.bin',    map_location='cpu')\nmodel.load_state_dict(state_dict, strict=False)\nmodel.eval()\n```\n\n## 2. Define a `predict` function\n\nNext, you will need to define a function that takes in the *user input*, which in this case is a sketched image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://huggingface.co/spaces/nateraw/quickdraw/blob/main/class_names.txt).\n\nIn the case of our pretrained model, it will look like this:\n\n```python\nfrom pathlib import Path\n\nLABELS = Path('class_names.txt').read_text().splitlines()\n\ndef predict(img):\n    x = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.\n    with torch.no_grad():\n        out = model(x)\n    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n    values, indices = torch.topk(probabilities, 5)\n    confidences = {LABELS[i]: v.item() for i, v in zip(indices, values)}\n    return confidences\n```\n\nLet's break this down. The function takes one parameters:\n\n* `img`: the input image as a `numpy` array\n\nThen, the function converts the image to a PyTorch `tensor`, passes it through the model, and returns:\n\n* `confidences`: the top five predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\n\n## 3. Create a Gradio Interface\n\nNow that we have our predictive function set up, we can create a Gradio Interface around it. \n\nIn this case, the input component is a sketchpad. To create a sketchpad input, we can use the convenient string shortcut, `\"sketchpad\"` which creates a canvas for a user to draw on and handles the preprocessing to convert that to a numpy array. \n\nThe output component will be a `\"label\"`, which displays the top labels in a nice form.\n\nFinally, we'll add one more parameter, setting `live=True`, which allows our interface to run in real time, adjusting its predictions every time a user draws on the sketchpad. The code for Gradio looks like this:\n\n```python\nimport gradio as gr\n\ngr.Interface(fn=predict, \n             inputs=\"sketchpad\",\n             outputs=\"label\",\n             live=True).launch()\n```\n\nThis produces the following interface, which you can try right here in your browser (try drawing something, like a \"snake\" or a \"laptop\"):\n\n<iframe src=\"https://abidlabs-draw2.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\n\n----------\n\nAnd you're done! That's all the code you need to build a Pictionary-style guessing app. Have fun and try to find some edge cases \ud83e\uddd0\n\n", "html": "<h1 id=\"building-a-pictionary-app\">Building a Pictionary App</h1>\n\n<h2 id=\"introduction\">Introduction</h2>\n\n<p>How well can an algorithm guess what you're drawing? A few years ago, Google released the <strong>Quick Draw</strong> dataset, which contains drawings made by humans of a variety of every objects. Researchers have used this dataset to train models to guess Pictionary-style drawings. </p>\n\n<p>Such models are perfect to use with Gradio's <em>sketchpad</em> input, so in this tutorial we will build a Pictionary web application using Gradio. We will be able to build the whole web application in Python, and will look like this (try drawing something!):</p>\n\n<iframe src=\"https://abidlabs-draw2.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\n\n<p>Let's get started! This guide covers how to build a pictionary app (step-by-step): </p>\n\n<ol>\n<li><a href=\"#1-set-up-the-sketch-recognition-model\">Set up the Sketch Recognition Model</a></li>\n<li><a href=\"#2-define-a-predict-function\">Define a <code>predict</code> function</a></li>\n<li><a href=\"#3-create-a-gradio-interface\">Create a Gradio Interface</a></li>\n</ol>\n\n<h3 id=\"prerequisites\">Prerequisites</h3>\n\n<p>Make sure you have the <code>gradio</code> Python package already <a rel=\"noopener\" target=\"_blank\" href=\"/getting_started\">installed</a>. To use the pretrained sketchpad model, also install <code>torch</code>.</p>\n\n<h2 id=\"1-set-up-the-sketch-recognition-model\">1. Set up the Sketch Recognition Model</h2>\n\n<p>First, you will need a sketch recognition model. Since many researchers have already trained their own models on the Quick Draw dataset, we will use a pretrained model in this tutorial. Our model is a light 1.5 MB  model trained by Nate Raw, that <a rel=\"noopener\" target=\"_blank\" href=\"https://huggingface.co/spaces/nateraw/quickdraw/blob/main/pytorch_model.bin\">you can download here</a>. </p>\n\n<p>If you are interested, here <a rel=\"noopener\" target=\"_blank\" href=\"https://github.com/nateraw/quickdraw-pytorch\">is the code</a> that was used to train the model. We will simply load the pretrained model in PyTorch, as follows:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import torch\nfrom torch import nn\n\nmodel = nn.Sequential(\n    nn.Conv2d(1, 32, 3, padding='same'),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Conv2d(32, 64, 3, padding='same'),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Conv2d(64, 128, 3, padding='same'),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Flatten(),\n    nn.Linear(1152, 256),\n    nn.ReLU(),\n    nn.Linear(256, len(LABELS)),\n)\nstate_dict = torch.load('pytorch_model.bin',    map_location='cpu')\nmodel.load_state_dict(state_dict, strict=False)\nmodel.eval()\n</code></pre></div>\n\n<h2 id=\"2-define-a-predict-function\">2. Define a <code>predict</code> function</h2>\n\n<p>Next, you will need to define a function that takes in the <em>user input</em>, which in this case is a sketched image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this <a rel=\"noopener\" target=\"_blank\" href=\"https://huggingface.co/spaces/nateraw/quickdraw/blob/main/class_names.txt\">text file</a>.</p>\n\n<p>In the case of our pretrained model, it will look like this:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>from pathlib import Path\n\nLABELS = Path('class_names.txt').read_text().splitlines()\n\ndef predict(img):\n    x = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.\n    with torch.no_grad():\n        out = model(x)\n    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n    values, indices = torch.topk(probabilities, 5)\n    confidences = {LABELS[i]: v.item() for i, v in zip(indices, values)}\n    return confidences\n</code></pre></div>\n\n<p>Let's break this down. The function takes one parameters:</p>\n\n<ul>\n<li><code>img</code>: the input image as a <code>numpy</code> array</li>\n</ul>\n\n<p>Then, the function converts the image to a PyTorch <code>tensor</code>, passes it through the model, and returns:</p>\n\n<ul>\n<li><code>confidences</code>: the top five predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities</li>\n</ul>\n\n<h2 id=\"3-create-a-gradio-interface\">3. Create a Gradio Interface</h2>\n\n<p>Now that we have our predictive function set up, we can create a Gradio Interface around it. </p>\n\n<p>In this case, the input component is a sketchpad. To create a sketchpad input, we can use the convenient string shortcut, <code>\"sketchpad\"</code> which creates a canvas for a user to draw on and handles the preprocessing to convert that to a numpy array. </p>\n\n<p>The output component will be a <code>\"label\"</code>, which displays the top labels in a nice form.</p>\n\n<p>Finally, we'll add one more parameter, setting <code>live=True</code>, which allows our interface to run in real time, adjusting its predictions every time a user draws on the sketchpad. The code for Gradio looks like this:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import gradio as gr\n\ngr.Interface(fn=predict, \n             inputs=\"sketchpad\",\n             outputs=\"label\",\n             live=True).launch()\n</code></pre></div>\n\n<p>This produces the following interface, which you can try right here in your browser (try drawing something, like a \"snake\" or a \"laptop\"):</p>\n\n<iframe src=\"https://abidlabs-draw2.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\n\n<hr />\n\n<p>And you're done! That's all the code you need to build a Pictionary-style guessing app. Have fun and try to find some edge cases \ud83e\uddd0</p>\n", "tags": ["SKETCHPAD", "LABELS", "LIVE"], "spaces": ["https://huggingface.co/spaces/nateraw/quickdraw"], "url": "/guides/building-a-pictionary-app/", "contributor": null}}