{"guide": {"name": "creating-a-chatbot", "category": "other-tutorials", "pretty_category": "Other Tutorials", "guide_index": null, "absolute_index": 32, "pretty_name": "Creating A Chatbot", "content": "# How to Create a Chatbot\n\nTags: NLP, TEXT, CHAT\nRelated spaces: https://huggingface.co/spaces/gradio/chatbot_streaming, https://huggingface.co/spaces/project-baize/Baize-7B, \n\n## Introduction\n\nChatbots are widely used in natural language processing (NLP) research and industry. Because chatbots are designed to be used directly by customers and end users, it is important to validate that chatbots are behaving as expected when confronted with a wide variety of input prompts.\n\nUsing `gradio`, you can easily build a demo of your chatbot model and share that with your users, or try it yourself using an intuitive chatbot GUI.\n\nThis tutorial will show how to make several kinds of chatbot UIs with Gradio: first a simple one to display text, second one to stream text responses, and finally a chatbot that can handle media files as well. The chatbot interface that we create will look something like this:\n\n<gradio-app space='gradio/chatbot_streaming'></gradio-app>\n\n**Prerequisite**: We'll be using the `gradio.Blocks` class to build our Chatbot demo.\nYou can [read the Guide to Blocks first](https://gradio.app/quickstart/#blocks-more-flexibility-and-control) if you are not already familiar with it. Also please make sure you are using the **latest version** version of Gradio: `pip install --upgrade gradio`. \n\n## A Simple Chatbot Demo\n\nLet's start with recreating the simple demo above. As you may have noticed, our bot simply randomly responds \"How are you?\", \"I love you\", or \"I'm very hungry\" to any input. Here's the code to create this with Gradio:\n\n```python\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    def respond(message, chat_history):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        chat_history.append((message, bot_message))\n        time.sleep(2)\n        return \"\", chat_history\n\n    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n\ndemo.launch()\n\n```\n\nThere are three Gradio components here:\n\n* A `Chatbot`, whose value stores the entire history of the conversation, as a list of response pairs between the user and bot.\n* A `Textbox` where the user can type their message, and then hit enter/submit to trigger the chatbot response\n* A `ClearButton` button to clear the Textbox and entire Chatbot history\n\nWe have a single function, `respond()`, which takes in the entire history of the chatbot, appends a random message, waits 1 second, and then returns the updated chat history. The `respond()` function also clears the textbox when it returns. \n\nOf course, in practice, you would replace `respond()` with your own more complex function, which might call a pretrained model or an API, to generate a response.\n\n<gradio-app space='gradio/chatbot_simple'></gradio-app>\n\n\n## Add Streaming to your Chatbot\n\nThere are several ways we can improve the user experience of the chatbot above. First, we can stream responses so the user doesn't have to wait as long for a message to be generated. Second, we can have the user message appear immediately in the chat history, while the chatbot's response is being generated. Here's the code to achieve that: \n\n```python\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.Button(\"Clear\")\n\n    def user(user_message, history):\n        return \"\", history + [[user_message, None]]\n\n    def bot(history):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        history[-1][1] = \"\"\n        for character in bot_message:\n            history[-1][1] += character\n            time.sleep(0.05)\n            yield history\n\n    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n    clear.click(lambda: None, None, chatbot, queue=False)\n    \ndemo.queue()\ndemo.launch()\n\n```\n\n\nYou'll notice that when a user submits their message, we now *chain* three event events with `.then()`:\n\n1. The first method `user()` updates the chatbot with the user message and clears the input field. This method also makes the input field non interactive so that the user can't send another message while the chatbot is responding. Because we want this to happen instantly, we set `queue=False`, which would skip any queue had it been enabled. The chatbot's history is appended with `(user_message, None)`, the `None` signifying that the bot has not responded.\n\n2. The second method, `bot()` updates the chatbot history with the bot's response. Instead of creating a new message, we just replace the previously-created `None` message with the bot's response. Finally, we construct the message character by character and `yield` the intermediate outputs as they are being constructed. Gradio automatically turns any function with the `yield` keyword [into a streaming output interface](/guides/key-features/#iterative-outputs).\n\n3. The third method makes the input field interactive again so that users can send another message to the bot.\n\nOf course, in practice, you would replace `bot()` with your own more complex function, which might call a pretrained model or an API, to generate a response.\n\nFinally, we enable queuing by running `demo.queue()`, which is required for streaming intermediate outputs. You can try the improved chatbot by scrolling to the demo at the top of this page.\n\n## Adding Markdown, Images, Audio, or Videos\n\nThe `gr.Chatbot` component supports a subset of markdown including bold, italics, and code. For example, we could write a function that responds to a user's message, with a bold **That's cool!**, like this:\n\n```py\ndef bot(history):\n    response = \"**That's cool!**\"\n    history[-1][1] = response\n    return history\n```\n\nIn addition, it can handle media files, such as images, audio, and video. To pass in a media file, we must pass in the file as a tuple of two strings, like this: `(filepath, alt_text)`. The `alt_text` is optional, so you can also just pass in a tuple with a single element `(filepath,)`, like this:\n\n```python\ndef add_file(history, file):\n    history = history + [((file.name,), None)]\n    return history\n```\n\nPutting this together, we can create a *multimodal* chatbot with a textbox for a user to submit text and an file upload button to submit images / audio / video files. The rest of the code looks pretty much the same as before:\n\n```python\nimport gradio as gr\nimport random\nimport time\n\n# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n\ndef add_text(history, text):\n    history = history + [(text, None)]\n    return history, gr.update(value=\"\", interactive=False)\n\n\ndef add_file(history, file):\n    history = history + [((file.name,), None)]\n    return history\n\n\ndef bot(history):\n    response = \"**That's cool!**\"\n    history[-1][1] = \"\"\n    for character in response:\n        history[-1][1] += character\n        time.sleep(0.05)\n        yield history\n\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot([], elem_id=\"chatbot\").style(height=750)\n\n    with gr.Row():\n        with gr.Column(scale=0.85):\n            txt = gr.Textbox(\n                show_label=False,\n                placeholder=\"Enter text and press enter, or upload an image\",\n            ).style(container=False)\n        with gr.Column(scale=0.15, min_width=0):\n            btn = gr.UploadButton(\"\ud83d\udcc1\", file_types=[\"image\", \"video\", \"audio\"])\n\n    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n        bot, chatbot, chatbot\n    )\n    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n\ndemo.queue()\ndemo.launch()\n\n```\n<gradio-app space='gradio/chatbot_multimodal'></gradio-app>\n\nAnd you're done! That's all the code you need to build an interface for your chatbot model. Finally, we'll end our Guide with some links to Chatbots that are running on Spaces so that you can get an idea of what else is possible:\n\n* [project-baize/Baize-7B](https://huggingface.co/spaces/project-baize/Baize-7B): A stylized chatbot that allows you to stop generation as well as regenerate responses. \n* [MAGAer13/mPLUG-Owl](https://huggingface.co/spaces/MAGAer13/mPLUG-Owl): A multimodal chatbot that allows you to upvote and downvote responses. \n", "html": "<h1 id=\"how-to-create-a-chatbot\">How to Create a Chatbot</h1>\n\n<h2 id=\"introduction\">Introduction</h2>\n\n<p>Chatbots are widely used in natural language processing (NLP) research and industry. Because chatbots are designed to be used directly by customers and end users, it is important to validate that chatbots are behaving as expected when confronted with a wide variety of input prompts.</p>\n\n<p>Using <code>gradio</code>, you can easily build a demo of your chatbot model and share that with your users, or try it yourself using an intuitive chatbot GUI.</p>\n\n<p>This tutorial will show how to make several kinds of chatbot UIs with Gradio: first a simple one to display text, second one to stream text responses, and finally a chatbot that can handle media files as well. The chatbot interface that we create will look something like this:</p>\n\n<p><gradio-app space='gradio/chatbot_streaming'></gradio-app></p>\n\n<p><strong>Prerequisite</strong>: We'll be using the <code>gradio.Blocks</code> class to build our Chatbot demo.\nYou can <a rel=\"noopener\" target=\"_blank\" href=\"https://gradio.app/quickstart/#blocks-more-flexibility-and-control\">read the Guide to Blocks first</a> if you are not already familiar with it. Also please make sure you are using the <strong>latest version</strong> version of Gradio: <code>pip install --upgrade gradio</code>. </p>\n\n<h2 id=\"a-simple-chatbot-demo\">A Simple Chatbot Demo</h2>\n\n<p>Let's start with recreating the simple demo above. As you may have noticed, our bot simply randomly responds \"How are you?\", \"I love you\", or \"I'm very hungry\" to any input. Here's the code to create this with Gradio:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    def respond(message, chat_history):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        chat_history.append((message, bot_message))\n        time.sleep(2)\n        return \"\", chat_history\n\n    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n\ndemo.launch()\n\n</code></pre></div>\n\n<p>There are three Gradio components here:</p>\n\n<ul>\n<li>A <code>Chatbot</code>, whose value stores the entire history of the conversation, as a list of response pairs between the user and bot.</li>\n<li>A <code>Textbox</code> where the user can type their message, and then hit enter/submit to trigger the chatbot response</li>\n<li>A <code>ClearButton</code> button to clear the Textbox and entire Chatbot history</li>\n</ul>\n\n<p>We have a single function, <code>respond()</code>, which takes in the entire history of the chatbot, appends a random message, waits 1 second, and then returns the updated chat history. The <code>respond()</code> function also clears the textbox when it returns. </p>\n\n<p>Of course, in practice, you would replace <code>respond()</code> with your own more complex function, which might call a pretrained model or an API, to generate a response.</p>\n\n<p><gradio-app space='gradio/chatbot_simple'></gradio-app></p>\n\n<h2 id=\"add-streaming-to-your-chatbot\">Add Streaming to your Chatbot</h2>\n\n<p>There are several ways we can improve the user experience of the chatbot above. First, we can stream responses so the user doesn't have to wait as long for a message to be generated. Second, we can have the user message appear immediately in the chat history, while the chatbot's response is being generated. Here's the code to achieve that: </p>\n\n<div class='codeblock'><pre><code class='lang-python'>import gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.Button(\"Clear\")\n\n    def user(user_message, history):\n        return \"\", history + [[user_message, None]]\n\n    def bot(history):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        history[-1][1] = \"\"\n        for character in bot_message:\n            history[-1][1] += character\n            time.sleep(0.05)\n            yield history\n\n    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n    clear.click(lambda: None, None, chatbot, queue=False)\n\ndemo.queue()\ndemo.launch()\n\n</code></pre></div>\n\n<p>You'll notice that when a user submits their message, we now <em>chain</em> three event events with <code>.then()</code>:</p>\n\n<ol>\n<li><p>The first method <code>user()</code> updates the chatbot with the user message and clears the input field. This method also makes the input field non interactive so that the user can't send another message while the chatbot is responding. Because we want this to happen instantly, we set <code>queue=False</code>, which would skip any queue had it been enabled. The chatbot's history is appended with <code>(user_message, None)</code>, the <code>None</code> signifying that the bot has not responded.</p></li>\n<li><p>The second method, <code>bot()</code> updates the chatbot history with the bot's response. Instead of creating a new message, we just replace the previously-created <code>None</code> message with the bot's response. Finally, we construct the message character by character and <code>yield</code> the intermediate outputs as they are being constructed. Gradio automatically turns any function with the <code>yield</code> keyword <a rel=\"noopener\" target=\"_blank\" href=\"/guides/key-features/#iterative-outputs\">into a streaming output interface</a>.</p></li>\n<li><p>The third method makes the input field interactive again so that users can send another message to the bot.</p></li>\n</ol>\n\n<p>Of course, in practice, you would replace <code>bot()</code> with your own more complex function, which might call a pretrained model or an API, to generate a response.</p>\n\n<p>Finally, we enable queuing by running <code>demo.queue()</code>, which is required for streaming intermediate outputs. You can try the improved chatbot by scrolling to the demo at the top of this page.</p>\n\n<h2 id=\"adding-markdown-images-audio-or-videos\">Adding Markdown, Images, Audio, or Videos</h2>\n\n<p>The <code>gr.Chatbot</code> component supports a subset of markdown including bold, italics, and code. For example, we could write a function that responds to a user's message, with a bold <strong>That's cool!</strong>, like this:</p>\n\n<div class='codeblock'><pre><code class='lang-py'>def bot(history):\n    response = \"**That's cool!**\"\n    history[-1][1] = response\n    return history\n</code></pre></div>\n\n<p>In addition, it can handle media files, such as images, audio, and video. To pass in a media file, we must pass in the file as a tuple of two strings, like this: <code>(filepath, alt_text)</code>. The <code>alt_text</code> is optional, so you can also just pass in a tuple with a single element <code>(filepath,)</code>, like this:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>def add_file(history, file):\n    history = history + [((file.name,), None)]\n    return history\n</code></pre></div>\n\n<p>Putting this together, we can create a <em>multimodal</em> chatbot with a textbox for a user to submit text and an file upload button to submit images / audio / video files. The rest of the code looks pretty much the same as before:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import gradio as gr\nimport random\nimport time\n\n# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n\ndef add_text(history, text):\n    history = history + [(text, None)]\n    return history, gr.update(value=\"\", interactive=False)\n\n\ndef add_file(history, file):\n    history = history + [((file.name,), None)]\n    return history\n\n\ndef bot(history):\n    response = \"**That's cool!**\"\n    history[-1][1] = \"\"\n    for character in response:\n        history[-1][1] += character\n        time.sleep(0.05)\n        yield history\n\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot([], elem_id=\"chatbot\").style(height=750)\n\n    with gr.Row():\n        with gr.Column(scale=0.85):\n            txt = gr.Textbox(\n                show_label=False,\n                placeholder=\"Enter text and press enter, or upload an image\",\n            ).style(container=False)\n        with gr.Column(scale=0.15, min_width=0):\n            btn = gr.UploadButton(\"\ud83d\udcc1\", file_types=[\"image\", \"video\", \"audio\"])\n\n    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n        bot, chatbot, chatbot\n    )\n    txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n\ndemo.queue()\ndemo.launch()\n\n</code></pre></div>\n\n<p><gradio-app space='gradio/chatbot_multimodal'></gradio-app></p>\n\n<p>And you're done! That's all the code you need to build an interface for your chatbot model. Finally, we'll end our Guide with some links to Chatbots that are running on Spaces so that you can get an idea of what else is possible:</p>\n\n<ul>\n<li><a rel=\"noopener\" target=\"_blank\" href=\"https://huggingface.co/spaces/project-baize/Baize-7B\">project-baize/Baize-7B</a>: A stylized chatbot that allows you to stop generation as well as regenerate responses. </li>\n<li><a rel=\"noopener\" target=\"_blank\" href=\"https://huggingface.co/spaces/MAGAer13/mPLUG-Owl\">MAGAer13/mPLUG-Owl</a>: A multimodal chatbot that allows you to upvote and downvote responses. </li>\n</ul>\n", "tags": ["NLP", "TEXT", "CHAT"], "spaces": ["https://huggingface.co/spaces/gradio/chatbot_streaming", "https://huggingface.co/spaces/project-baize/Baize-7B", ""], "url": "/guides/creating-a-chatbot/", "contributor": null}}