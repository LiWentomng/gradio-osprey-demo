{"guide": {"name": "advanced-interface-features", "category": "building-interfaces", "pretty_category": "Building Interfaces", "guide_index": 4, "absolute_index": 6, "pretty_name": "Advanced Interface Features", "content": "# Advanced Interface Features\n\nThere's more to cover on the [Interface](https://gradio.app/docs#interface) class. This guide covers all the advanced features: Using [Interpretation](https://gradio.app/docs#interpretation), custom styling, loading from the [Hugging Face Hub](https://hf.co), and using [Parallel](https://gradio.app/docs#parallel) and [Series](https://gradio.app/docs#series). \n\n## Interpreting your Predictions\n\nMost models are black boxes such that the internal logic of the function is hidden from the end user. To encourage transparency, we've made it very easy to add interpretation to your model by  simply setting the `interpretation` keyword in the `Interface` class to `default`. This allows your users to understand what parts of the input are responsible for the output. Take a look at the simple interface below which shows an image classifier that also includes interpretation:\n\n```python\nimport requests\nimport tensorflow as tf\n\nimport gradio as gr\n\ninception_net = tf.keras.applications.MobileNetV2()  # load the model\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\n\ndef classify_image(inp):\n    inp = inp.reshape((-1, 224, 224, 3))\n    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n    prediction = inception_net.predict(inp).flatten()\n    return {labels[i]: float(prediction[i]) for i in range(1000)}\n\n\nimage = gr.Image(shape=(224, 224))\nlabel = gr.Label(num_top_classes=3)\n\ndemo = gr.Interface(\n    fn=classify_image, inputs=image, outputs=label, interpretation=\"default\"\n)\n\ndemo.launch()\n\n```\n\n\nIn addition to `default`, Gradio also includes [Shapley-based interpretation](https://christophm.github.io/interpretable-ml-book/shap.html), which provides more accurate interpretations, albeit usually with a slower runtime. To use this, simply set the `interpretation` parameter to `\"shap\"` (note: also make sure the python package `shap` is installed). Optionally, you can modify the `num_shap` parameter, which controls the tradeoff between accuracy and runtime (increasing this value generally increases accuracy). Here is an example:\n\n```python\ngr.Interface(fn=classify_image,\n            inputs=image, \n            outputs=label, \n            interpretation=\"shap\", \n            num_shap=5).launch()\n```\n\nThis will work for any function, even if internally, the model is a complex neural network or some other black box. If you use Gradio's `default` or `shap` interpretation, the output component must be a `Label`. All common input components are supported. Here is an example with text input.\n\n```python\nimport gradio as gr\n\nmale_words, female_words = [\"he\", \"his\", \"him\"], [\"she\", \"hers\", \"her\"]\n\n\ndef gender_of_sentence(sentence):\n    male_count = len([word for word in sentence.split() if word.lower() in male_words])\n    female_count = len(\n        [word for word in sentence.split() if word.lower() in female_words]\n    )\n    total = max(male_count + female_count, 1)\n    return {\"male\": male_count / total, \"female\": female_count / total}\n\n\ndemo = gr.Interface(\n    fn=gender_of_sentence,\n    inputs=gr.Textbox(value=\"She went to his house to get her keys.\"),\n    outputs=\"label\",\n    interpretation=\"default\",\n)\n\ndemo.launch()\n\n```\n\nSo what is happening under the hood? With these interpretation methods, Gradio runs the prediction multiple times with modified versions of the input. Based on the results, you'll see that the interface automatically highlights the parts of the text (or image, etc.) that contributed increased the likelihood of the class as red. The intensity of color corresponds to the importance of that part of the input. The parts that decrease the class confidence are highlighted blue.\n\nYou can also write your own interpretation function. The demo below adds custom interpretation to the previous demo. This function will take the same inputs as the main wrapped function. The output of this interpretation function will be used to highlight the input of each input component - therefore the function must return a list where the number of elements corresponds to the number of input components. To see the format for interpretation for each input component, check the Docs.\n\n```python\nimport re\n\nimport gradio as gr\n\nmale_words, female_words = [\"he\", \"his\", \"him\"], [\"she\", \"hers\", \"her\"]\n\n\ndef gender_of_sentence(sentence):\n    male_count = len([word for word in sentence.split() if word.lower() in male_words])\n    female_count = len(\n        [word for word in sentence.split() if word.lower() in female_words]\n    )\n    total = max(male_count + female_count, 1)\n    return {\"male\": male_count / total, \"female\": female_count / total}\n\n\n# Number of arguments to interpretation function must\n# match number of inputs to prediction function\ndef interpret_gender(sentence):\n    result = gender_of_sentence(sentence)\n    is_male = result[\"male\"] > result[\"female\"]\n    interpretation = []\n    for word in re.split(\"( )\", sentence):\n        score = 0\n        token = word.lower()\n        if (is_male and token in male_words) or (not is_male and token in female_words):\n            score = 1\n        elif (is_male and token in female_words) or (\n            not is_male and token in male_words\n        ):\n            score = -1\n        interpretation.append((word, score))\n    # Output must be a list of lists containing the same number of elements as inputs\n    # Each element corresponds to the interpretation scores for the given input\n    return [interpretation]\n\n\ndemo = gr.Interface(\n    fn=gender_of_sentence,\n    inputs=gr.Textbox(value=\"She went to his house to get her keys.\"),\n    outputs=\"label\",\n    interpretation=interpret_gender,\n)\n\ndemo.launch()\n\n```\n\nLearn more about Interpretation in the [docs](https://gradio.app/docs#interpretation). \n\n## Custom Styling\n\nIf you'd like to have more fine-grained control over any aspect of your demo, you can also write your own css or pass in a filepath to a css file, with the `css` parameter of the `Interface` class.\n\n```python\ngr.Interface(..., css=\"body {background-color: red}\")\n```\n\nIf you'd like to reference external files in your css, preface the file path (which can be a relative or absolute path) with `\"file=\"`, for example:\n\n```python\ngr.Interface(..., css=\"body {background-image: url('file=clouds.jpg')}\")\n```\n\n**Warning**: Custom CSS is *not* guaranteed to work across Gradio versions as the Gradio HTML DOM may change. We recommend using custom CSS sparingly and instead using [Themes](/guides/theming-guide/) whenever possible. \n\n## Loading Hugging Face Models and Spaces\n\nGradio integrates nicely with the [Hugging Face Hub](https://hf.co), allowing you to load models and Spaces with just one line of code. To use this, simply use the `load()` method in the `Interface` class. So:\n\n- To load any model from the Hugging Face Hub and create an interface around it, you pass `\"model/\"` or `\"huggingface/\"` followed by the model name, like these examples:\n\n```python\ngr.Interface.load(\"huggingface/gpt2\").launch();\n```\n\n```python\ngr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\", \n    inputs=gr.Textbox(lines=5, label=\"Input Text\")  # customizes the input component\n).launch()\n```\n\n- To load any Space from the Hugging Face Hub and recreate it locally (so that you can customize the inputs and outputs for example), you pass `\"spaces/\"` followed by the model name:\n\n```python\ngr.Interface.load(\"spaces/eugenesiow/remove-bg\", \n                  inputs=\"webcam\", \n                  title=\"Remove your webcam background!\").launch()\n```\n\nOne of the great things about loading Hugging Face models or spaces using Gradio is that you can then immediately use the resulting `Interface` object just like function in your Python code (this works for every type of model/space: text, images, audio, video, and even multimodal models):\n\n```python\nio = gr.Interface.load(\"models/EleutherAI/gpt-neo-2.7B\")\nio(\"It was the best of times\")  # outputs model completion\n```\n\n## Putting Interfaces in Parallel and Series\n\nGradio also lets you mix interfaces very easily using the `gradio.Parallel` and `gradio.Series` classes. `Parallel` lets you put two similar models (if they have the same input type) in parallel to compare model predictions:\n\n```python\ngenerator1 = gr.Interface.load(\"huggingface/gpt2\")\ngenerator2 = gr.Interface.load(\"huggingface/EleutherAI/gpt-neo-2.7B\")\ngenerator3 = gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\")\n\ngr.Parallel(generator1, generator2, generator3).launch()\n```\n\n`Series` lets you put models and spaces in series, piping the output of one model into the input of the next model. \n\n```python\ngenerator = gr.Interface.load(\"huggingface/gpt2\")\ntranslator = gr.Interface.load(\"huggingface/t5-small\")\n\ngr.Series(generator, translator).launch()  \n# this demo generates text, then translates it to German, and outputs the final result.\n```\n\nAnd of course, you can also mix `Parallel` and `Series` together whenever that makes sense!\n\nLearn more about Parallel and Series in the [docs](https://gradio.app/docs#parallel). ", "html": "<h1 id=\"advanced-interface-features\">Advanced Interface Features</h1>\n\n<p>There's more to cover on the <a rel=\"noopener\" target=\"_blank\" href=\"https://gradio.app/docs#interface\">Interface</a> class. This guide covers all the advanced features: Using <a rel=\"noopener\" target=\"_blank\" href=\"https://gradio.app/docs#interpretation\">Interpretation</a>, custom styling, loading from the <a rel=\"noopener\" target=\"_blank\" href=\"https://hf.co\">Hugging Face Hub</a>, and using <a rel=\"noopener\" target=\"_blank\" href=\"https://gradio.app/docs#parallel\">Parallel</a> and <a rel=\"noopener\" target=\"_blank\" href=\"https://gradio.app/docs#series\">Series</a>. </p>\n\n<h2 id=\"interpreting-your-predictions\">Interpreting your Predictions</h2>\n\n<p>Most models are black boxes such that the internal logic of the function is hidden from the end user. To encourage transparency, we've made it very easy to add interpretation to your model by  simply setting the <code>interpretation</code> keyword in the <code>Interface</code> class to <code>default</code>. This allows your users to understand what parts of the input are responsible for the output. Take a look at the simple interface below which shows an image classifier that also includes interpretation:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import requests\nimport tensorflow as tf\n\nimport gradio as gr\n\ninception_net = tf.keras.applications.MobileNetV2()  # load the model\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\n\ndef classify_image(inp):\n    inp = inp.reshape((-1, 224, 224, 3))\n    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n    prediction = inception_net.predict(inp).flatten()\n    return {labels[i]: float(prediction[i]) for i in range(1000)}\n\n\nimage = gr.Image(shape=(224, 224))\nlabel = gr.Label(num_top_classes=3)\n\ndemo = gr.Interface(\n    fn=classify_image, inputs=image, outputs=label, interpretation=\"default\"\n)\n\ndemo.launch()\n\n</code></pre></div>\n\n<p>In addition to <code>default</code>, Gradio also includes <a rel=\"noopener\" target=\"_blank\" href=\"https://christophm.github.io/interpretable-ml-book/shap.html\">Shapley-based interpretation</a>, which provides more accurate interpretations, albeit usually with a slower runtime. To use this, simply set the <code>interpretation</code> parameter to <code>\"shap\"</code> (note: also make sure the python package <code>shap</code> is installed). Optionally, you can modify the <code>num_shap</code> parameter, which controls the tradeoff between accuracy and runtime (increasing this value generally increases accuracy). Here is an example:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>gr.Interface(fn=classify_image,\n            inputs=image, \n            outputs=label, \n            interpretation=\"shap\", \n            num_shap=5).launch()\n</code></pre></div>\n\n<p>This will work for any function, even if internally, the model is a complex neural network or some other black box. If you use Gradio's <code>default</code> or <code>shap</code> interpretation, the output component must be a <code>Label</code>. All common input components are supported. Here is an example with text input.</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import gradio as gr\n\nmale_words, female_words = [\"he\", \"his\", \"him\"], [\"she\", \"hers\", \"her\"]\n\n\ndef gender_of_sentence(sentence):\n    male_count = len([word for word in sentence.split() if word.lower() in male_words])\n    female_count = len(\n        [word for word in sentence.split() if word.lower() in female_words]\n    )\n    total = max(male_count + female_count, 1)\n    return {\"male\": male_count / total, \"female\": female_count / total}\n\n\ndemo = gr.Interface(\n    fn=gender_of_sentence,\n    inputs=gr.Textbox(value=\"She went to his house to get her keys.\"),\n    outputs=\"label\",\n    interpretation=\"default\",\n)\n\ndemo.launch()\n\n</code></pre></div>\n\n<p>So what is happening under the hood? With these interpretation methods, Gradio runs the prediction multiple times with modified versions of the input. Based on the results, you'll see that the interface automatically highlights the parts of the text (or image, etc.) that contributed increased the likelihood of the class as red. The intensity of color corresponds to the importance of that part of the input. The parts that decrease the class confidence are highlighted blue.</p>\n\n<p>You can also write your own interpretation function. The demo below adds custom interpretation to the previous demo. This function will take the same inputs as the main wrapped function. The output of this interpretation function will be used to highlight the input of each input component - therefore the function must return a list where the number of elements corresponds to the number of input components. To see the format for interpretation for each input component, check the Docs.</p>\n\n<div class='codeblock'><pre><code class='lang-python'>import re\n\nimport gradio as gr\n\nmale_words, female_words = [\"he\", \"his\", \"him\"], [\"she\", \"hers\", \"her\"]\n\n\ndef gender_of_sentence(sentence):\n    male_count = len([word for word in sentence.split() if word.lower() in male_words])\n    female_count = len(\n        [word for word in sentence.split() if word.lower() in female_words]\n    )\n    total = max(male_count + female_count, 1)\n    return {\"male\": male_count / total, \"female\": female_count / total}\n\n\n# Number of arguments to interpretation function must\n# match number of inputs to prediction function\ndef interpret_gender(sentence):\n    result = gender_of_sentence(sentence)\n    is_male = result[\"male\"] > result[\"female\"]\n    interpretation = []\n    for word in re.split(\"( )\", sentence):\n        score = 0\n        token = word.lower()\n        if (is_male and token in male_words) or (not is_male and token in female_words):\n            score = 1\n        elif (is_male and token in female_words) or (\n            not is_male and token in male_words\n        ):\n            score = -1\n        interpretation.append((word, score))\n    # Output must be a list of lists containing the same number of elements as inputs\n    # Each element corresponds to the interpretation scores for the given input\n    return [interpretation]\n\n\ndemo = gr.Interface(\n    fn=gender_of_sentence,\n    inputs=gr.Textbox(value=\"She went to his house to get her keys.\"),\n    outputs=\"label\",\n    interpretation=interpret_gender,\n)\n\ndemo.launch()\n\n</code></pre></div>\n\n<p>Learn more about Interpretation in the <a rel=\"noopener\" target=\"_blank\" href=\"https://gradio.app/docs#interpretation\">docs</a>. </p>\n\n<h2 id=\"custom-styling\">Custom Styling</h2>\n\n<p>If you'd like to have more fine-grained control over any aspect of your demo, you can also write your own css or pass in a filepath to a css file, with the <code>css</code> parameter of the <code>Interface</code> class.</p>\n\n<div class='codeblock'><pre><code class='lang-python'>gr.Interface(..., css=\"body {background-color: red}\")\n</code></pre></div>\n\n<p>If you'd like to reference external files in your css, preface the file path (which can be a relative or absolute path) with <code>\"file=\"</code>, for example:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>gr.Interface(..., css=\"body {background-image: url('file=clouds.jpg')}\")\n</code></pre></div>\n\n<p><strong>Warning</strong>: Custom CSS is <em>not</em> guaranteed to work across Gradio versions as the Gradio HTML DOM may change. We recommend using custom CSS sparingly and instead using <a rel=\"noopener\" target=\"_blank\" href=\"/guides/theming-guide/\">Themes</a> whenever possible. </p>\n\n<h2 id=\"loading-hugging-face-models-and-spaces\">Loading Hugging Face Models and Spaces</h2>\n\n<p>Gradio integrates nicely with the <a rel=\"noopener\" target=\"_blank\" href=\"https://hf.co\">Hugging Face Hub</a>, allowing you to load models and Spaces with just one line of code. To use this, simply use the <code>load()</code> method in the <code>Interface</code> class. So:</p>\n\n<ul>\n<li>To load any model from the Hugging Face Hub and create an interface around it, you pass <code>\"model/\"</code> or <code>\"huggingface/\"</code> followed by the model name, like these examples:</li>\n</ul>\n\n<div class='codeblock'><pre><code class='lang-python'>gr.Interface.load(\"huggingface/gpt2\").launch();\n</code></pre></div>\n\n<div class='codeblock'><pre><code class='lang-python'>gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\", \n    inputs=gr.Textbox(lines=5, label=\"Input Text\")  # customizes the input component\n).launch()\n</code></pre></div>\n\n<ul>\n<li>To load any Space from the Hugging Face Hub and recreate it locally (so that you can customize the inputs and outputs for example), you pass <code>\"spaces/\"</code> followed by the model name:</li>\n</ul>\n\n<div class='codeblock'><pre><code class='lang-python'>gr.Interface.load(\"spaces/eugenesiow/remove-bg\", \n                  inputs=\"webcam\", \n                  title=\"Remove your webcam background!\").launch()\n</code></pre></div>\n\n<p>One of the great things about loading Hugging Face models or spaces using Gradio is that you can then immediately use the resulting <code>Interface</code> object just like function in your Python code (this works for every type of model/space: text, images, audio, video, and even multimodal models):</p>\n\n<div class='codeblock'><pre><code class='lang-python'>io = gr.Interface.load(\"models/EleutherAI/gpt-neo-2.7B\")\nio(\"It was the best of times\")  # outputs model completion\n</code></pre></div>\n\n<h2 id=\"putting-interfaces-in-parallel-and-series\">Putting Interfaces in Parallel and Series</h2>\n\n<p>Gradio also lets you mix interfaces very easily using the <code>gradio.Parallel</code> and <code>gradio.Series</code> classes. <code>Parallel</code> lets you put two similar models (if they have the same input type) in parallel to compare model predictions:</p>\n\n<div class='codeblock'><pre><code class='lang-python'>generator1 = gr.Interface.load(\"huggingface/gpt2\")\ngenerator2 = gr.Interface.load(\"huggingface/EleutherAI/gpt-neo-2.7B\")\ngenerator3 = gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\")\n\ngr.Parallel(generator1, generator2, generator3).launch()\n</code></pre></div>\n\n<p><code>Series</code> lets you put models and spaces in series, piping the output of one model into the input of the next model. </p>\n\n<div class='codeblock'><pre><code class='lang-python'>generator = gr.Interface.load(\"huggingface/gpt2\")\ntranslator = gr.Interface.load(\"huggingface/t5-small\")\n\ngr.Series(generator, translator).launch()  \n# this demo generates text, then translates it to German, and outputs the final result.\n</code></pre></div>\n\n<p>And of course, you can also mix <code>Parallel</code> and <code>Series</code> together whenever that makes sense!</p>\n\n<p>Learn more about Parallel and Series in the <a rel=\"noopener\" target=\"_blank\" href=\"https://gradio.app/docs#parallel\">docs</a>. </p>\n", "tags": [], "spaces": [], "url": "/guides/advanced-interface-features/", "contributor": null}}